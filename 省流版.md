> 建议直接看省流版


[toc]
### 综述

<div align=center>
<img src="./figures/C1-1-LLMs_0623_final.png">
</div>

### 大模型能力探究

#### In Context Learning 

`In-Context learning（ICL）`最早在`GPT3`中提出, 旨在从训练集中挑选少量的标注样本，设计任务相关的指令形成提示模板，用于指导测试样本生成相应的结果，有以下三种学习方式。
![](./figures/incontextlearning.png)

#### 涌现能力
涌现能力是大模型区别小模型最显著的特征之一。

- **上下文学习ICL**:ICL 能力是由 GPT-3 正式引入的:假设已经为语言模型提供了一个自然语言指令和或几个任务演示，它可以通过完成输入文本的单词序列的方式来为测试实例生成预期的输出，而无需额外的训练或梯度更新

- **指令微调IFT**:通过使用自然语言描述的混合多任务数据集进行微调(称为指令微调)，LLM在未见过的以指令形式描述的任务上表现出色。通过指令微调，LLM 能够在没有使用显式示例的情况下遵循新的任务指令，因此它具有更好的泛化能力。

- **逐步推理COT**:对于小型语言模型而言，通常很难解决涉及多个推理步骤的复杂任务，例如数学问题。然而，通过使用思维链(Chain-of-Thought, CoT)提示策略，LLM 可以通过利用包含中间推理步骤的提示机制来解决这类任务，从而得出最终答案。

#### 能力评估

#### 领域能力

---

### Transformer

#### Transformer 工作原理

> 参见 [什么是 GPT？Transformer 工作原理的动画展示](https://arthurchiao.art/blog/visual-intro-to-transformers-zh/)

![](https://arthurchiao.art/assets/img/visual-intro-to-transformers/transformer-modules.gif)

> 更多可查看
> 
> - [Transformer模型详解（图解最完整版](https://zhuanlan.zhihu.com/p/338817680)
> - [OpenAI ChatGPT（一）：十分钟读懂 Transformer](https://zhuanlan.zhihu.com/p/600773858)
> - [Transformer的结构是什么样的？各个子模块各有什么作用？](https://blog.csdn.net/m0_54929869/article/details/118881804)
> - [以Transformer结构为基础的大模型参数量、计算量、中间激活以及KV cache剖析](https://mp.weixin.qq.com/s/3JYz6yrLeBr5ujip3LZe6w)
> - [Transformer 一起动手编码学原理](https://mp.weixin.qq.com/s/NgUNuWhvp2SqG-XWYv2PGQ)
> - [为什么transformer(Bert)的多头注意力要对每一个head进行降维？](http://www.sniper97.cn/index.php/note/deep-learning/note-deep-learning/4002/)


#### Transformer 实现

> 参见 [Transformer 是如何工作的：600 行 Python 代码实现 self-attention 和两类 Transformer](https://arthurchiao.art/blog/transformers-from-scratch-zh/)

---
<details>

<summary>代码如下</summary>

**`text classification transformer`** 的`python`实现

    ```python
    class Transformer(nn.Module):
    def __init__(self, k, heads, depth, seq_length, num_tokens, num_classes):
        super().__init__()

        self.num_tokens = num_tokens
        self.token_emb = nn.Embedding(num_tokens, k)
        self.pos_emb = nn.Embedding(seq_length, k)

        # The sequence of transformer blocks that does all the heavy lifting
        tblocks = []
        for i in range(depth):
            tblocks.append(TransformerBlock(k=k, heads=heads))
        self.tblocks = nn.Sequential(*tblocks)

        # Maps the final output sequence to class logits
        self.toprobs = nn.Linear(k, num_classes)

    def forward(self, x):
        """
        :param x: A (b, t) tensor of integer values representing words (in some predetermined vocabulary).
        :return: A (b, c) tensor of log-probabilities over the classes (where c is the nr. of classes).
        """
        # generate token embeddings
        tokens = self.token_emb(x)
        b, t, k = tokens.size()

        # generate position embeddings
        positions = torch.arange(t)
        positions = self.pos_emb(positions)[None, :, :].expand(b, t, k)

        x = tokens + positions # 为什么文本嵌入和位置嵌入相加，没有理论，可能就是实验下来效果不错。
                               # https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/
        x = self.tblocks(x)

        # Average-pool over the t dimension and project to class
        # probabilities
        x = self.toprobs(x.mean(dim=1))
        return F.log_softmax(x, dim=1)
    ```

</details>

---

> 更多可查看
> 
> - [OpenAI ChatGPT（一）：Tensorflow实现Transformer](https://zhuanlan.zhihu.com/p/603243890)
> - [OpenAI ChatGPT（一）：十分钟读懂 Transformer](https://zhuanlan.zhihu.com/p/600773858)
> - [GPT （一）transformer原理和代码详解](https://zhuanlan.zhihu.com/p/632880248)
> - [Transformer源码详解（Pytorch版本）](https://zhuanlan.zhihu.com/p/398039366)
> - [搞懂Transformer结构，看这篇PyTorch实现就够了](https://zhuanlan.zhihu.com/p/339207092)


encoder-decoder or encoder-only
decoder-only


---


### 主流LLMS和预训练

<div align=center>
<img src="./figures/C1-4-flow_chart.png">
</div>

预训练数据在大语言模型的开发中起着关键作用。

作为 LLM 超能力(remarkable capabilities)的基础， 预训练数据的质量、数量和多样性显著影响 LLM 的性能。 常用的预训练数据包括多种文本数据，例如书籍、文章和网站。 数据经过精心挑选，以确保全面代表人类知识、语言差别和文化观点。

预训练数据的重要性在于，它能够极大影响语言模型对词汇知识、语法、句法和语义的理解，以及识别上下文和生成连贯回答的能力。 预训练数据的多样性也对模型性能起着至关重要的作用，LLM 的性能高度依赖于预训练数据的组成。

简而言之，在针对 NLP 任务做 LLM 选型时，建议选择那些在类似数据领域上进行过预训练的模型。

分类：
- 自回归语言模型Language Modeling（LM）：基于序列前面的token自回归地预测当前token，一般目标函数为最大化似然函数。
- 去噪语言建模Denoising Autoencoding(DAE)：类似于bert的mlm预测任务，mask掉某个词，根据上下文预测mask掉的词。一般应用在plm语言模型中。
- 
主流模型架构的对比图，包括因果编码器、前缀解码器和编码器-解码器架构
  
---

### Prompt Tunning范式

![](https://images.datacamp.com/image/upload/v1716225433/image_5c7e44724a.png)

![](./figures/PromptTunning.png)

Prompt-Tuning方法是一种用于改进语言模型的训练方法，是由谷歌提出的一种轻量级的优化方法。在语言模型中，Prompt是一个前缀文本，用于指导生成的文本内容。Prompt-Tuning方法通过对Prompt进行优化，使其能够更好地引导模型生成符合预期的文本。

- 基于Fine-Tuning的方法是让预训练模型去迁就下游任务，
- 基于Prompt-Tuning的方法可以让下游任务去迁就预训练模型, 其目的是将Fine-tuning的下游任务目标转换为Pre-training的任务.

#### Tunning Free Prompt
#### Fix-Prompt LM Tunning
#### Fix-LM Prompt Tunning
#### Fix-LM Adapter Tunning
#### Representation Tuning


---

### 指令微调&对齐 (instruction_tunning)

指令微调是在自然语言格式的实例(instance)集合上微调预训练后的 LLM 的方法


![](./figures/intructionturing.png)


#### 经典方案
#### SFT数据Scaling Law
#### 新对齐/微调方案
#### 指令数据生成
#### 如何降低通用能力损失
#### 微调经验/实验报告

---
### RLHF

与指令微调不同，对齐微调可能需要考虑一些标准，有用性（简单回答用户问题）、诚实性（回答问题不捏造）、无害性（回答问题不具伤害性）等。

人类对llm输出的主观和定性评估对llm学习人类偏好和价值观非常有用。

通常通过3种方式来收集人类反馈：

- 基于排序方法，以列表的方式选出最好的一个选项，可能会忽略其他的情况。组成pair构建哪个更好的方式能获取更多的信息。

- 基于问题的方法：给出一些关于此次模型输出 是否有用/诚实/无害的判断类问题，人类需要对这些问题选择选- 项进行回答，这些将作为反馈。

- 基于规则的方法：设定一些规则或者训练一个反馈模型判断该反馈是否带有有害内容。

![](./figures/workflow.png)

![](./figures/RLTF.png)


#### Deepmind
#### openai
#### Inference Scaling
#### 改良方案
#### RL探究
---
### 对话模型
---
### 思维链 (prompt_chain_of_thought)
思维链(Chain-of-Thought，CoT)是一种改进的提示策略，旨在提高 LLM 在复杂推理任务中的性能，例如算术推理 ，常识推理 和符号推理。不同于 ICL 中仅使用输入输出对来构造提示，CoT 将可以导出最终输出的中间推理步骤纳入提示中。

思维链方法的核心思想是将思考的过程及其相关的观念和想法串联起来，形成一个连续的思维链条。这种链条可以由线性或非线性的思维过程构成，从而帮助模型不断延伸和扩展思考。相比于之前传统的上下文学习（即通过x1,y1,x2 ,y2 ,....xtest作为输入来让大模型补全输出ytest），思维链多了中间的推导提示.

#### 原理分析
![](./figures/cot.png)

#### 基础&进阶用法
#### 非传统COT问题分解方向
#### 分领域COT [Math, Code, Tabular, QA]

---------

### RAG

#### 相关工作总结

**![](https://lh7-rt.googleusercontent.com/slidesz/AGV_vUfjnIeg74h1klbjyLlhYAV-bFUhaHYjMwt1ynD7A051RtNTrXwzRMytaaFNDnpM-21y15WRynSsDGcW28MEaFb2vuOK-AERkeOLhI0yilG0Ud6OzGeNK_HmmhKU0BgAYB2Awr0zsRj5XSZY2ZwXvfzyEutfpAM=nw?key=ZqWaY0jBtWrtvi15fPc-Fw)**

![](https://s2.loli.net/2024/03/15/CaWpDAZhPE753Jw.png)

#### 相关技术要点

<img src = './figures/8bcf9de22af50e0d74e7d5e4d0eabde.png'/>

#### 技术框架
![](https://s2.loli.net/2024/03/15/Sk6mgsKFuzJPyrN.png)

#### RAG 研究热点
![](https://s2.loli.net/2024/03/15/zj7AmBVOIe5WL2U.png)

#### RAG 的挑战
- 长上下文
- 与FT的协同
- 如何应用好LLM，充分挖掘利用LLM
- 提升鲁棒性，比如如何处理错误的召回内容，如何过滤和验证召回内容
- RAG 是否也遵循Scaling Law
- 最佳工程实践，比如提升在大数据量下的检索延迟，如何保障隐私的检索内容不被LLM泄露

![](https://s2.loli.net/2024/03/15/L9b6at48WTOnBDd.png)

#### 多模态扩展
将RAG从文本扩展到多模态
![](https://s2.loli.net/2024/03/15/rxOjqaiUZcJE1tD.png)

#### RAG 开发生态建设
扩展RAG下游任务，改善生态建设

![](https://s2.loli.net/2024/03/15/AJtDsSQp4iWTfVo.png)

#### RAG 技术栈与工业界实践
当前有`LangChain`、`LlamaIndex`、`AutoGen`等流行的开发框架，可以方便开发RAG应用。

![](https://s2.loli.net/2024/03/15/OoHTMZzPR3IYjCx.png)

工业界也有很多RAG应用。

![](https://s2.loli.net/2024/03/15/MxZKr9WYy4UnSBv.png)


[RAG详细代码](https://github.com/langchain-ai/rag-from-scratch/tree/main)(路径：LLM\rag-from-scratch-main)


-----------

### LLM Agent 让模型使用工具 (llm_agent)

![](./figures/1004194-20240418201738953-1952968254.png)

- 具备独立思考和自主决策的能力，
- 输出结果不依赖于prompt的清晰程度

**AI Agent = LLM大模型 + Planning规划 + Memory记忆 + Tool Use工具使用**

![](./figures/1004194-20240418182653018-347518787.png)

#### 基于prompt通用方案
#### 基于微调通用方案
#### 调用模型方案
#### 垂直领域
#### 评估
#### MultiAgent
#### 自主学习和探索进化

--------

### 大模型图表理解和生成
#### survey
#### prompt 
#### fintuning
#### multimodal

-------------

### LLM+KG
#### 综述类
#### KG用于大模型推理
#### 大模型用于KG构建

----------

### Humanoid Agents
---------

### pretrain_data & pretrain
----------

### 领域模型SFT(domain_llms)
-----------

### LLM超长文本处理 (long_input)
#### 位置编码、注意力机制优化
#### 上文压缩排序方案
#### 训练和模型架构方案
#### 效率优化

-----------
### LLM长文本生成（long_output）
----------

### NL2SQL
#### 大模型方案
#### Domain Knowledge Intensive
#### others
-----------

### Code Generation

------------
### 降低模型幻觉 (reliability)

在生成事实文本时，一个具有挑战性的问题是幻觉生成 ，即生成的信息与现有来源相冲突(内在幻觉)或无法通过现有来源验证(外在幻觉)。

#### Survey 
#### Prompt or Tunning
#### Decoding Strategy
#### Probing and Detection
#### Reviewing and Calibration
--------

### 大模型评估（evaluation）

llm主要关注3种评估任务，语言生成、知识利用、复杂推理。

语言生成主要有3种任务，语言模型、条件文本生成、代码合成。

语言生成分类:
- 语言模型：根据上文token预测下一个token，一般根据困惑度、预测token的准确度指标来评估模型

- 条件文本生成：基于给定的条件生成满足特定任务需求的文本，通常包括机器翻译 、文本摘要和问答系统，使用自动化指标(如准确率、BLEU 和 ROUGE )和人类评分来评估性能

- 代码合成:除了生成高质量的自然语言外，现有的 LLM 还表现出强大的生成形式语言的能力，尤其是满足特定条件的计算机程序(即代码)，这种能力被称为代码合成。计算测试用例的通过率(即 pass@k)来评估 LLM 生成的代码的质量

#### 事实性评估
#### 检测任务
----------
### 推理优化(inference)
--------

### 模型知识编辑黑科技(model_edit)
-------

### 模型合并和剪枝(model_merge)
---------

### MOE
--------

### Other Prompt Engineer(prompt_engineer)
--------

### Multimodal
----------

### Timeseries LLM
---------

### Quanization
--------

### Adversarial Attacking
-------

### Others
------


### LLM资源合集

#### 论文
[论文合集](https://github.com/asimsinan/LLM-Research/blob/main/Papers.md)(截止2024/9/26)

#### 课程

[课程合集](https://github.com/asimsinan/LLM-Research/blob/main/UniversityCourses.md)：

#### 框架

[框架合集](https://github.com/asimsinan/LLM-Research/blob/main/ToolsFrameworks.md)


#### 模型
[模型汇总](https://github.com/DSXiangLi/DecryptPrompt/blob/main/%E5%BC%80%E6%BA%90%E6%A8%A1%E5%9E%8B.MD)


#### 数据

[开源数据](https://github.com/DSXiangLi/DecryptPrompt/blob/main/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE.MD)


